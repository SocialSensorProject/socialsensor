%!TEX root = document.tex

%start with a clean argument then fill in details.  
%Motivation is mostly the same, 
%contributions are different... we combine recent ideas on learning social sensors 
%	(you need to cite / cover what these ideas are to indicate what you're combining / building on -- perhaps being clear to point out that no single paper did everything you are doing) and then claim that beyond a general performance analysis of the framework over a variety of topics and a long-term dataset (not done previously?) 
%a key objective of the work is to provide a comprehensive longitudinal feature analysis to investigate XXX



\label{sec:introduction}
% Motivation
Social media sites such as Twitter present a double-edged sword for
users.  On one hand these sources contain a vast amount of novel and
topical content that challenge traditional news media sources in terms
of their timeliness and diversity.  Yet on the other hand they also
contain a vast amount of spam and otherwise low-value content for most
users' information needs where filtering out irrelevant content is
extremely time-consuming.  Hence, while it is widely acknowledged that
social media sources can be used as topical content sensors (indeed,
an entire European Union project was focused on related ``Social Sensor''
research\footnote{\texttt{http://www.socialsensor.eu/}}.),
automatically learning high-precision sensors (i.e., ranking and
retrieval methods) for arbitrary topics that generalize to future
unseen content have been addressed recently only by a handful of researchers \citep{lin2011smoothing,yang2014large,magdy}.
% and comprises the key problem we seek to address in this paper.

% Contribution 
% 1. One sentense: what do we do, combine, provide supervised learning, none of them has done all
% 2. What did existing works do?
% 3. How did we approach the problem? Build on existing ideas or expanded them?
% 4: What is the differences?

In this work, we coalesce recent ideas on learning social sensors for general topic detection. We expand these works to learn a generalizable supervised method with minimal user curation for detecting and ranking topical content over a variety of topics and on a long-term dataset. We believe that none of the earlier works covers all the aspect of the work that is presented here. 
%We contribute a supervised method for training
%social sensors with minimal user curation by using a small seed set of
%hashtags as topical proxies for automatic supervised data labeling. This works is built on the existing literature on detection and tracking general topics from social media \citep{lin2011smoothing,yang2014large,magdy}.
Recently, \citep{lin2011smoothing,yang2014large,magdy} have explored use of social media sensors for detection and/or tracking of general topics from Twitter. One of the key challenges on dealing with general topics and large number of tweets is automatic labeled data aquisition. \cite{lin2011smoothing} discusses automatic labeling of tweets by using one hashtag as topic proxy. \cite{magdy} uses a user-defined query to label tweets and \cite{yang2014large} takes a co-training approach based on embedded URLs in the tweet and tweet text to label tweets. We build and extend on \citep{lin2011smoothing}'s idea of automatic labeling of tweets, however we choose a set of hashtags for each topic instead of a single hashtag which we will show to be imperative for evaluating generalization. To learn social sensors for general topic detection, \citep{lin2011smoothing} uses information retrieval method (language models), \cite{yang2014large} take advantage of topic modeling techniques and \cite{magdy} applies SVM classifier. Here, we leverage various supervised learning methods for the purpose of detection and ranking of topical content. However, we present a unique method for splitting hashtags and Twitter data that encourages generalization to new unseen future content. 
%The methodologies mentioned in the literature use various sets of feature including hashtags, unigrams, bigrams, mentions, users, byte 4grams. We extract the main features of hashtags, mentions, users, unigrams. In addition, we add location as another set of features which we show later in feature analysis that location is the second most important feature for detection of topical content and some of the topics are quite localized geographically. To address general topic detection from social media, \cite{lin2011smoothing} uses information retrieval method (language models), \cite{yang2014large} take advantage of topic modeling techniques and \cite{magdy} uses SVM classifier. Here, we leverage various supervised learning methods for the purpose of detection and ranking of topical content. However, we present a unique method for splitting hashtags and Twitter data that encourages generalization to new unseen future content. 
Then we proceed to train supervised classification and ranking methods
to learn topical content from a large feature space of source users
and their locations, terms, hashtags, and mentions.  On a corpus of
over 800 million English Tweets collected from the Twitter streaming
API during 2013 and 2014 and covering 10 diverse topics ranging from
"social issues" to "celebrity deaths" to the "Iran nuclear deal'', we
empirically show that two simple and efficiently trainable methods ---
logistic regression and naive Bayes --- generalize well to unseen
future topical content (including content with no hashtags) in terms
of their mean average precision (MAP) and Precision@$n$ for a range of
$n$. Our results suggest that these
sensors generalize well to unseen future topical content and provide a
novel paradigm for the extraction of high-value content from social
media.  Furthermore, we show that terms and locations are among the most
useful features --- surprisingly more so than hashtags, even though
hashtags were used to label the data.  And perhaps even more
surprisingly, the number of unique hashtags and tweets by a user
correlates more with their informativeness than their follower or
friend count.
 
In summary, we build on the recent existing works on tracking general topics and we expand these works by (1) providing a long-term study on performance of the detectors, (2) testing future generalization to novel topical content, (3) providing a novel and comprehensive longitudinal feature analysis to investigate the importance of features and their attributes in regards to detection of topical content. 

%In this work, we contribute a supervised method for training
%social sensors with minimal user curation by using a small seed set of
%hashtags as topical proxies for automatic supervised data labeling.
%Then we proceed to train supervised classification and ranking methods
%to learn topical content from a large feature space of source users
%and their locations, terms, hashtags, and mentions.  On a corpus of
%over 800 million English Tweets collected from the Twitter streaming
%API during 2013 and 2014 and covering 10 diverse topics ranging from
%social issues to celebrity deaths to the ``Iran nuclear deal'', we
%empirically show that two simple and efficiently trainable methods ---
%logistic regression and naive Bayes --- generalize well to unseen
%future topical content (including content with no hashtags) in terms
%of their mean average precision (MAP) and Precision@$n$ for a range of
%$n$.  Furthermore, we show that terms and locations are among the most
%useful features --- surprisingly more so than hashtags, even though
%hashtags were used to label the data.  And perhaps even more
%surprisingly, the number of unique hashtags and tweets by a user
%correlates more with their informativeness than their follower or
%friend count.
%
%Overall, our feature analysis indicates that the most
%useful features are sometimes counter-intuitive and that in general
%learning methods may be much more effective than manual engineering
%for building topical social sensors.
%
%In summary, this work fills a major gap in 
%event detection and tracking from social media
%%\eat{the literature of topical social sensors and } 
%on identifying emerging topics from long-running themes with
%%\eat{how to effectively and efficiently learn them given}
%minimal user supervision.  Our results suggest that these
%sensors generalize well to unseen future topical content and provide a
%novel paradigm for the extraction of high-value content from social
%media.
%
%Twitter hosts lots of information, on average more than $2,200$ new tweets every second. This can get up to $3$ to $4$ times increase during large events such as tsunami. \footnote{\hyperref[]{https://blog.twitter.com/2011/the-engineering-behind-twitter-s-new-search-experience}}
%\begin{itemize}
%\item Twitter is a vast sensor of content generated by latent phenonema (e.g., flu, political sentiment, elections, environment).
%\item Learning topical social sensors (politicians in NY, road conditions in Toronto) -- very broad topics for which its hard to manually specify a useful query.
%\item But there is interesting topical content and wouldn't it be cool if we could learn a social sensor for a targeted topic?
%\item Key insight is that hashtags are topical and can be used to bootstrap a supervised learning system that as we will show generalizes well beyond the seed hashtags.
%\item Conclusion is a new way to build topical real-time feeds that are otherwise difficult to do with existing Twitter tools (???).
%\end{itemize}
%section{Learning Topical Social Sensors}

%Start off with the questions that we want to answer in this section:
%
%- How to evaluate, labeling (problem of no supervised labels for tweets, indirect via hashtags as topical surrogates, leads to question of hashtag curation)?
%
%- Which classification algorithm is best / most robust for learning topical social sensors?
